# -*- coding: utf-8 -*-
"""Cópia de Trabalho Big Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FZAqWGyiGSk1Va2QIvNw_llfF1JeRF6w

#**Setup**

Importação das principais bilbiotecas ultilizadas
"""

# Carregamento e manipulação dos dados
import pandas as pd
import numpy as np

# Visualização de dados
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px

# Preparação dos dados
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder

# Modelos de aprendizado de máquina
# Classificação
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier

# Regressão
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor

# Avaliação de modelos
from sklearn import metrics
from sklearn.metrics import mean_squared_error, r2_score

# Instalação de dependências (caso necessário)
!pip install -U kaleido

print("Todas as bibliotecas foram importadas com sucesso!")

"""Carregue a base de dados."""

df = pd.read_excel("/content/Dados_abertos_Consumo_Mensal (1).xlsx")

df

"""#**Pré-processamento dos dados**

Identificação de Linhas e Colunas
"""

df.shape

"""Identificar informações do dataset"""

df.info()

"""Realize uma descrição estatística dos dados"""

descricao = df.describe()
print(descricao)

"""Visualiza as distribuições e identifica a relevância das colunas para a análise"""

print("Primeiras linhas do DataFrame:")
print(df.head())

"""Quantidade de registros de cada região"""

df["Regiao"].value_counts()

"""Distribuições dos valores Númericos (Data, DataExcel, Consumo, Consumidores)"""

df.hist(bins=30, figsize=(15, 10))
plt.suptitle('Distribuição das Colunas Numéricas')
plt.show()

"""Verifica a presença de dados nulos, duplicados, outliers e demais inconsistências
nos dados
"""

print("\nDados Nulos por Coluna:")
print(df.isnull().sum())

"""Verifica linhas duplicados"""

print("\nNúmero de Linhas Duplicadas:")
print(df.duplicated().sum())

"""Tratando os tipos de dados

Dados do tipo float não tem boa performance nos modelos, logo precisamos trata-los para int. Temos apenas os dados de Consumo como float.
"""

df["Consumo"] = df["Consumo"].astype(int)

df.dtypes

df

"""Criação da coluna Mês. Importante para termos a visualização mais detalhada do passar do tempo nos nossos dados."""

df["Mes"] = df["DataExcel"].dt.month

df

"""#**Análise exploratória dos dados**

**Plotagem de gráficos para análise**

Iniciamos usando um Histograma para ver como está distribuido cada classe de consumidores.

Onde podemos ver que as duas classes com mais registros são industrial e comercial, e a classe com menos registros é residencial.
"""

df['Classe'].hist(bins=10);

"""Depois ainda usando o Histograma, verificamos a distribuição entre as regiões.

Vemos que a região com mais registros são as regiões Norte e Nordeste, e as com menos registros são as Sul e Sudeste.
"""

df['Regiao'].hist(bins=10);

"""Por último verificamos a distribuição de registros por tipo de consumidor.

Sendo um consumidor cativo aquele que não tem liberdade de selecionar o seu fornecedor de energia, e o livre tem a possibilidade de escolher.
"""

df['TipoConsumidor'].hist(bins=10);

"""Mais importante do que os registros, temos que saber como o consumo em si é distribuido, para isso começamos montando gráficos de barra do consumo sobre o tipo de consumidor.

Conforme o Gráfico vemos que o consumo cativo é o maior que o livre.
"""

# Agrupar os dados por região e somar o consumo
consumo_por_tipo_consumidor = df.groupby('TipoConsumidor')['Consumo'].sum()

# Criando o gráfico de barras
plt.figure(figsize=(10, 6))
sns.barplot(x=consumo_por_tipo_consumidor.index, y=consumo_por_tipo_consumidor.values, hue=consumo_por_tipo_consumidor, palette='viridis')
plt.title('Consumo por Tipo de Consumidor')
plt.xlabel('Tipo de Consumidor')
plt.ylabel('Consumo (MWh)')
plt.legend(title='Consumo (MWh)', loc='upper right')
plt.tight_layout()
plt.show()

"""Fazendo o mesmo para a região, nesse caso foi necessário agrupar os dados para cada região, temos um resultado diferente do número de registros.


Mesmo tendo pouco registros, a região sudeste teve um valor de consumo muito maior do que as outras regiões.
"""

# Agrupar os dados por região e somar o consumo
consumo_por_regiao = df.groupby('Regiao')['Consumo'].sum()

# Criar o gráfico de barras com cores diferentes para cada região
plt.figure(figsize=(12, 6))
sns.barplot(x=consumo_por_regiao.index, y=consumo_por_regiao.values, hue=consumo_por_regiao, palette='viridis')
plt.title('Consumo por Região')
plt.xlabel('Região')
plt.ylabel('Consumo Total (MWh)')
plt.legend(title='Consumo Total (MWh)', loc='upper right')
plt.xticks(rotation=45, ha='right') # Rotacionar rótulos do eixo x para melhor legibilidade
plt.tight_layout() # Ajusta o layout para evitar sobreposição de elementos
plt.show()

"""Resolvemos fazer uma análise temporal do consumo por região ao longo do tempo.

Como podemos ver, a região Sudeste foi desde o começo da análise a região com mais consumo.

Além disso vemos que não teve grandes alterações no nível de consumo de cada região no período analisado.
"""

# Criando a série temporal
consumo_por_regiao_e_data = df.groupby(['DataExcel', 'Regiao'])['Consumo'].sum().reset_index()

# Criando o gráfico de linhas para visualizar a série temporal
plt.figure(figsize=(15, 8))
for regiao in consumo_por_regiao_e_data['Regiao'].unique():
  subset = consumo_por_regiao_e_data[consumo_por_regiao_e_data['Regiao'] == regiao]
  plt.plot(subset['DataExcel'], subset['Consumo'], label=regiao)

plt.title('Consumo por Região ao Longo do Tempo')
plt.xlabel('DataExcel')
plt.ylabel('Consumo (MWh)')
plt.xticks(rotation=45, ha='right')
plt.legend()
plt.tight_layout()
plt.show()

"""Da mesma forma que fizemos com as regiões resolvemos fazer também com as Classes de cada consumidor.

E vemos um notável aumento no consumo da classe residencial, mesmo lembrando que ela foi a classe com menos registros no nosso estudo.

Logo vemos um aumento temporal notável em cada registro da classe residencial.
"""

# Criando a série temporal
consumo_por_classe_e_data = df.groupby(['DataExcel', 'Classe'])['Consumo'].sum().reset_index()

# Criando o gráfico de linhas para visualizar a série temporal
plt.figure(figsize=(15, 8))
for classe in consumo_por_classe_e_data['Classe'].unique():
  subset = consumo_por_classe_e_data[consumo_por_classe_e_data['Classe'] == classe]
  plt.plot(subset['DataExcel'], subset['Consumo'], label=classe)

plt.title('Consumo por Classe ao Longo do Tempo')
plt.xlabel('DataExcel')
plt.ylabel('Consumo (MWh)')
plt.xticks(rotation=45, ha='right')
plt.legend()
plt.tight_layout()
plt.show()

"""Com isso em mente, decidimos realizar a mesma análise mas apenas para os dados dos tipo de consumidores cativos.

Isolamos todos os registros Cativos e fizemos o mesmo teste.

Na análise percebemos a grande queda do regime Cativo na Classe Industrial. E uma certa estabilidade na distribuição de cada outra classe. Em destaque a classe Residencial que tem grande parte dela sendo de regime cativo.
"""

# Filtrando o DataFrame para incluir apenas o tipo de consumo 'Cativo'
df_cativo = df[df['TipoConsumidor'] == 'Cativo']

# Criando a série temporal para o consumo cativo
consumo_por_classe_e_data = df_cativo.groupby(['DataExcel', 'Classe'])['Consumo'].sum().reset_index()

# Criando o gráfico de linhas para visualizar a série temporal
plt.figure(figsize=(15, 8))
for classe in consumo_por_classe_e_data['Classe'].unique():
  subset = consumo_por_classe_e_data[consumo_por_classe_e_data['Classe'] == classe]
  plt.plot(subset['DataExcel'], subset['Consumo'], label=classe)

plt.title('Consumo por Classe Cativo ao Longo do Tempo')
plt.xlabel('DataExcel')
plt.ylabel('Consumo MWh')
plt.xticks(rotation=45, ha='right')
plt.legend()
plt.tight_layout()
plt.savefig("consumo_cativo.png", dpi=300, bbox_inches='tight')
plt.show()

"""Para verificar se a queda dos tipos de consumidores cativos da classe industrial realizaram uma migração para tipos livres, ou simplesmente diminuiram a quantidade de consumo dessa classe, fazemos o mesmo agrupamento anterior mas usando apenas tipos de consumidores livres, e com esses dados podems ver o aumento dos tipos de consumidores livres da classe industrial."""

# Filtrando o DataFrame para incluir apenas o tipo de consumo 'Livre'
df_livre = df[df['TipoConsumidor'] == 'Livre']

consumo_por_classe_e_data = df_livre.groupby(['DataExcel', 'Classe'])['Consumo'].sum().reset_index()

# Criando o gráfico de linhas para visualizar a série temporal
plt.figure(figsize=(15, 8))
for classe in consumo_por_classe_e_data['Classe'].unique():
  subset = consumo_por_classe_e_data[consumo_por_classe_e_data['Classe'] == classe]
  plt.plot(subset['DataExcel'], subset['Consumo'], label=classe)

plt.title('Consumo por Classe Livre ao Longo do Tempo')
plt.xlabel('DataExcel')
plt.ylabel('Consumo MWh')
plt.xticks(rotation=45, ha='right')
plt.legend()
plt.tight_layout()
plt.show()

"""#**Estruturação do Modelo**

Antes de montar nossos modelos em si, temos que transformar as nossas variáveis categoricas em valores númericos.

Como as variáveis já tem valores conhecidos optamos por usar o get_dummies para a transformação das variáveis.
"""

df_encoded = pd.get_dummies(df, columns=["Regiao", "Sistema", "Classe", "TipoConsumidor"])

"""Definimos variáveis de entrada (X) e saída (Y)"""

X = df_encoded[[col for col in df_encoded.columns if col.startswith(('Regiao', 'Sistema', 'Classe', 'TipoConsumidor')) or col == 'DataExcel']]
Y = df["Consumo"]

"""Transformamos os dados da Data em inteiros também para trabalhar esses dados nos nossos modelos."""

X['DataExcel'] = pd.to_datetime(X['DataExcel']).apply(lambda date: date.toordinal())

"""Dividimos os dados em treino e teste"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)

"""Resolvemos adotar 3 modelos de predição:

- Random Forest
- Regressão Linear
- Árvore de Decisão

Começamos treinando o modelo de random forest
"""

model = RandomForestRegressor(random_state=42)
model.fit(X_train, Y_train)

"""Fazendo previsões"""

y_pred_random = model.predict(X_test)

"""Avaliando o modelo"""

rmse = np.sqrt(mean_squared_error(Y_test, y_pred_random))
r2 = r2_score(Y_test, y_pred_random)

print(f"Random Forest - RMSE: {rmse}")
print(f"Random Forest - R²: {r2}")

"""Agora indo para Árvore de Decisão"""

dt = DecisionTreeRegressor()
dt.fit(X_train, Y_train)

"""Fazendo a predição"""

y_pred_tree = dt.predict(X_test)
y_pred_tree

"""Avaliando a Árvore de Decisão"""

rmse_tree = np.sqrt(mean_squared_error(Y_test, y_pred_tree))
r2_tree = r2_score(Y_test, y_pred_tree)
print(f"Árvore de Decisão - RMSE: {rmse_tree}")
print(f"Árvore de Decisão - R²: {r2}")

"""Treinando a Regressão Linear"""

linear_model = LinearRegression()
linear_model.fit(X_train, Y_train)

"""Fazendo a predição"""

y_pred_linear = linear_model.predict(X_test)
y_pred_linear

"""Avaliando a Regressão Linear"""

rmse_linear = np.sqrt(mean_squared_error(Y_test, y_pred_linear))
r2_linear = r2_score(Y_test, y_pred_linear)
print(f"Regressão Linear - RMSE: {rmse_linear}")
print(f"Regressão Linear - R²: {r2_linear}")

"""#**Construção dos Resultados**

Para ter uma visualização melhor da perfomance montamos scatterplot para cada modelo, comparando o dado real do predito

Começando com o Random Forest temos o seguinte gráfico
"""

px.scatter(x=Y_test, y=y_pred_random, title= "Real X predito", trendline="ols", labels={"x":"Real", "y":"Previsto"})

"""Agora indo para a Regressão Linear"""

px.scatter(x=Y_test, y=y_pred_linear, title= "Real X predito", trendline="ols", labels={"x":"Real", "y":"Previsto"})

"""E por último testando a Árvore de Decisão"""

px.scatter(x=Y_test, y=y_pred_tree, title= "Real X predito", trendline="ols", labels={"x":"Real", "y":"Previsto"})

"""Tabela dos Resultados"""

# Criar o DataFrame com os modelos ajustados
data = {'Modelo': ['Random Forest Regressor', 'Linear Regression', 'Decision Tree Regressor'],
        'RMSE': [rmse, rmse_linear, np.sqrt(mean_squared_error(Y_test, y_pred_tree))],
        'R²': [r2, r2_linear, r2_score(Y_test, y_pred_tree)]}
df_modelos = pd.DataFrame(data)

# Encontrando o melhor modelo para cada métrica
best_rmse_model = df_modelos.loc[df_modelos['RMSE'].idxmin()]
best_r2_model = df_modelos.loc[df_modelos['R²'].idxmax()]

# Formatando os melhores resultados em negrito
def format_table(df_results):
    formatted_data = []
    for _, row in df_results.iterrows():
        formatted_row = []
        for col in df_results.columns:
            value = row[col]
            if row['Modelo'] == best_rmse_model['Modelo'] or row['Modelo'] == best_r2_model['Modelo']:
                if col in ['RMSE', 'R²']:
                    formatted_row.append(f"$\\bf{{{value:.4f}}}$")  # Negrito para valores numéricos
                else:
                    formatted_row.append(f"$\\bf{{{value}}}$")  # Negrito para texto
            else:
                if col in ['RMSE', 'R²']:
                    formatted_row.append(f"{value:.4f}")  # Formatação numérica padrão
                else:
                    formatted_row.append(str(value))
        formatted_data.append(formatted_row)
    return formatted_data

# Criar uma figura e um eixo
fig, ax = plt.subplots(figsize=(8, 3))

# Ocultar eixos
ax.axis('off')

# Criar a tabela com os nomes ajustados
tabela = ax.table(cellText=format_table(df_modelos),
                  colLabels=df_modelos.columns,
                  cellLoc='center',
                  loc='center')

# Ajustar estilo
tabela.auto_set_font_size(False)
tabela.set_fontsize(10)
tabela.auto_set_column_width([0, 1, 2])

# Ajustar escala para melhor exibição
tabela.scale(1.5, 1.5)

# Salvar como PNG
plt.savefig("tabela.png", dpi=300, bbox_inches='tight')

# Exibir a imagem
plt.show()

"""Avaliação dos Resultados

**RMSE (Root Mean Square Error):**

O RMSE é uma métrica que mede o erro médio entre os valores preditos pelo modelo (Y_pred) e os valores reais (Y_test). Um RMSE de 46.238 indica que, em média, o modelo está errando a previsão do consumo por cerca de 46.238 unidades. Quanto menor o RMSE, melhor o desempenho do modelo, pois isso significa que o erro médio está mais próximo de zero.

**R² (Coeficiente de Determinação):**

O R² mede o quanto o modelo consegue explicar a variância dos dados. Ele varia de 0 a 1, onde:
- 0 significa que o modelo não explica nada dos dados.
- 1 significa que o modelo explica 100% da variância nos dados.

Um valor de 0.998 indica que o modelo explica quase toda a variância dos dados (99.8%). Isso é excelente, sugerindo que o modelo está fazendo previsões bastante precisas.
"""
